{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bc2bb5-d10c-4d15-af5a-ef7b85bd5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c41b048-eacb-47d3-af45-350e71ebbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() \n",
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dd6c6d-46b5-4d13-831b-bb3a572f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b42b12d-42e6-4efc-a0ba-0914a22c486d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(X_train[142], cmap=\"binary\") \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ea4e02-e980-4a32-80fa-e0c76d72c606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"koszulka\", \"spodnie\", \"pulower\", \"sukienka\", \"kurtka\",\n",
    "               \"sanda≈Ç\", \"koszula\", \"but\", \"torba\", \"kozak\"]\n",
    "class_names[y_train[142]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d343087-92b4-4d5a-b291-4dc644ef5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"image_logs\") \n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0354e51-9acb-4e04-8345-14ff72c61264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a18d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 300)               9300      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,771\n",
      "Trainable params: 39,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25ac08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \"fashion_mnist.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9172553-ffb1-4fda-874d-b313d57655bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 8s 3ms/step - loss: 0.7138 - accuracy: 0.7635 - val_loss: 0.5424 - val_accuracy: 0.8112\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4889 - accuracy: 0.8317 - val_loss: 0.4702 - val_accuracy: 0.8352\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4449 - accuracy: 0.8462 - val_loss: 0.4318 - val_accuracy: 0.8458\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4182 - accuracy: 0.8531 - val_loss: 0.4327 - val_accuracy: 0.8488\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3979 - accuracy: 0.8606 - val_loss: 0.4104 - val_accuracy: 0.8582\n",
      "Epoch 6/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3825 - accuracy: 0.8661 - val_loss: 0.4134 - val_accuracy: 0.8537\n",
      "Epoch 7/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3664 - accuracy: 0.8701 - val_loss: 0.3877 - val_accuracy: 0.8622\n",
      "Epoch 8/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3554 - accuracy: 0.8738 - val_loss: 0.3692 - val_accuracy: 0.8712\n",
      "Epoch 9/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3442 - accuracy: 0.8789 - val_loss: 0.3611 - val_accuracy: 0.8710\n",
      "Epoch 10/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3341 - accuracy: 0.8806 - val_loss: 0.3583 - val_accuracy: 0.8752\n",
      "Epoch 11/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3252 - accuracy: 0.8847 - val_loss: 0.3600 - val_accuracy: 0.8738\n",
      "Epoch 12/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3172 - accuracy: 0.8863 - val_loss: 0.3699 - val_accuracy: 0.8702\n",
      "Epoch 13/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3096 - accuracy: 0.8896 - val_loss: 0.3499 - val_accuracy: 0.8725\n",
      "Epoch 14/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3023 - accuracy: 0.8914 - val_loss: 0.3481 - val_accuracy: 0.8765\n",
      "Epoch 15/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.8947 - val_loss: 0.3357 - val_accuracy: 0.8777\n",
      "Epoch 16/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2906 - accuracy: 0.8965 - val_loss: 0.3338 - val_accuracy: 0.8775\n",
      "Epoch 17/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2838 - accuracy: 0.8976 - val_loss: 0.3284 - val_accuracy: 0.8832\n",
      "Epoch 18/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2776 - accuracy: 0.9013 - val_loss: 0.3263 - val_accuracy: 0.8813\n",
      "Epoch 19/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2725 - accuracy: 0.9011 - val_loss: 0.3410 - val_accuracy: 0.8747\n",
      "Epoch 20/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2668 - accuracy: 0.9045 - val_loss: 0.3157 - val_accuracy: 0.8842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_split=0.1, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79d862b-e703-476d-9d84-90403dfcd589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "Prediction: torba\n",
      "Confidence: 0.99864036\n",
      "Truth: torba\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = np.random.randint(len(X_test))\n",
    "image = np.array([X_test[image_index]])\n",
    "confidences = model.predict(image)\n",
    "confidence = np.max(confidences[0])\n",
    "prediction = np.argmax(confidences[0])\n",
    "print(\"Prediction:\", class_names[prediction])\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Truth:\", class_names[y_test[image_index]])\n",
    "plt.imshow(image[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4b0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c932122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1988), started 0:32:05 ago. (Use '!kill 1988' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21bc26dbd2bf6d28\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21bc26dbd2bf6d28\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./image_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c431774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fashion_clf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99429c5b-3d2c-4650-ad4c-7ad37464f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6403fed-9b92-452d-9c30-29f44eb24ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e86b7b28-9342-44de-8410-27a620cfb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a86b6867-c229-44fc-b7f3-4b3bfeec893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94253758-92e1-407c-88eb-5e60654c6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"softmax\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b4139d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dff9fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"housing_logs\") \n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b920bb0a-83e8-47e3-aeae-d43439a2f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.01,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "923a6da0-08ae-47c2-8e3b-b9cd51c3143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.5773 - val_loss: 1.2602\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2683 - val_loss: 1.2231\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2224 - val_loss: 1.1626\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1367 - val_loss: 1.0366\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9620 - val_loss: 0.8188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7633 - val_loss: 0.6553\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6526 - val_loss: 0.5828\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6033 - val_loss: 0.5483\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5733 - val_loss: 0.5243\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5485 - val_loss: 0.4996\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5249 - val_loss: 0.4781\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5019 - val_loss: 0.4555\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4350\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4161\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4008\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.3889\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4173 - val_loss: 0.3794\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.3734\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.3689\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4003 - val_loss: 0.3651\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 0.3628\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.3599\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.3582\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.3571\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.3561\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.3545\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d36fe-f43b-410c-922c-248e3bfddc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_housing_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c99c2986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1988), started 0:50:31 ago. (Use '!kill 1988' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-88afb3bf2ce30d3f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-88afb3bf2ce30d3f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./image_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b773418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94750999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,401\n",
      "Trainable params: 4,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.6286 - val_loss: 1.3174\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3409 - val_loss: 1.3191\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3408 - val_loss: 1.3171\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3405 - val_loss: 1.3158\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3407 - val_loss: 1.3162\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3406 - val_loss: 1.3201\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"softmax\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(100, activation=\"softmax\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"housing_logs/housing_logs_2\") \n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.01,verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cee85337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_housing_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bc3ae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1988), started 0:52:30 ago. (Use '!kill 1988' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6c73c63a82ec4a43\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6c73c63a82ec4a43\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./image_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "833d6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "816aad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 300)               9300      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,771\n",
      "Trainable params: 39,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3364 - val_loss: 1.1259\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.8951 - val_loss: 0.6400\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6316 - val_loss: 0.5644\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5590 - val_loss: 0.4986\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.5145 - val_loss: 0.4482\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4799 - val_loss: 0.4204\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4482 - val_loss: 0.4302\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4222 - val_loss: 0.4036\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.3648\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.3960\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.3557\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.3493\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.3388\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3423\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3423\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.3345\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3639\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3639 - val_loss: 0.3401\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"softmax\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(100, activation=\"tanh\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"housing_logs/housing_logs_3\") \n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.01,verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a970b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_housing_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "534f7d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1988), started 0:55:04 ago. (Use '!kill 1988' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e198d86096c0cd74\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e198d86096c0cd74\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./image_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9da446d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 300)               2700      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3000)              903000    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1000)              3001000   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,907,701\n",
      "Trainable params: 3,907,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 6.1586 - val_loss: 1.3801\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3545 - val_loss: 1.4593\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.2198 - val_loss: 0.6957\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8006 - val_loss: 0.6030\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6766 - val_loss: 0.5399\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6164 - val_loss: 0.5245\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5726 - val_loss: 0.4989\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5498 - val_loss: 0.4828\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.4638\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4949 - val_loss: 0.6022\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4937 - val_loss: 0.4135\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4726 - val_loss: 0.3908\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4664 - val_loss: 0.4051\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4534 - val_loss: 0.3760\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4515 - val_loss: 0.3774\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.3831\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4436 - val_loss: 0.3744\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.3625\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4341 - val_loss: 0.8043\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.5103\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.3841\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4166 - val_loss: 0.5232\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4207 - val_loss: 0.4994\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(3000, activation=\"sigmoid\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1000, activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"housing_logs/housing_logs_4\") \n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.01,verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d3bbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('reg_housing_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4f09910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1988), started 0:57:21 ago. (Use '!kill 1988' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e950fcb1d4569247\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e950fcb1d4569247\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./image_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
